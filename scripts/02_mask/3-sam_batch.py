import cv2
import torch
import numpy as np
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
import os
import sys
from pathlib import Path
from tqdm import tqdm
import time

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º UTF-8
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# è·å–é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)

# é…ç½®å‚æ•°
INPUT_DIR = os.path.join(PROJECT_ROOT, "data", "real")  # è¾“å…¥å›¾ç‰‡ç›®å½•
OUTPUT_DIR = os.path.join(PROJECT_ROOT, "data", "mask")  # è¾“å‡ºæ©ç ç›®å½•
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")  # æ—¥å¿—ç›®å½•
CKPT_PATH = os.path.join(PROJECT_ROOT, "checkpoints", "sam", "sam_vit_b_01ec64.pth")
MODEL_TYPE = "vit_b"  # å¯é€‰: "vit_b", "vit_l", "vit_h"

# å›¾åƒç¼©æ”¾é…ç½®
MAX_IMAGE_SIZE = 800  # å›¾åƒæœ€å¤§è¾¹é•¿ï¼ˆåƒç´ ï¼‰ï¼Œæ›´ä¿å®ˆçš„è®¾ç½®ç¡®ä¿8GBæ˜¾å­˜å¤Ÿç”¨
RESIZE_ENABLED = True  # æ˜¯å¦å¯ç”¨å›¾åƒç¼©æ”¾

# æ©ç é¢œè‰²é…ç½®
INVERT_MASK = True  # True=æ©ç åŒºåŸŸé»‘è‰²(0)ï¼ŒèƒŒæ™¯ç™½è‰²(255)ï¼›False=æ©ç åŒºåŸŸç™½è‰²(255)ï¼ŒèƒŒæ™¯é»‘è‰²(0)

# SAM å‚æ•°é…ç½®
SAM_PARAMS = {
    'points_per_side': 16,  # ä»32é™åˆ°16ï¼ˆå‡å°‘é‡‡æ ·ç‚¹ï¼Œé™ä½æ˜¾å­˜å ç”¨ï¼‰
    'pred_iou_thresh': 0.88,
    'stability_score_thresh': 0.95,
    'crop_n_layers': 0,  # ä»1é™åˆ°0ï¼ˆä¸è£å‰ªï¼Œå¤§å¹…é™ä½æ˜¾å­˜ï¼‰
    'min_mask_region_area': 500  # ä»200æé«˜åˆ°500ï¼ˆè¿‡æ»¤å°åŒºåŸŸï¼‰
}

# æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡
SKIP_EXISTING = True

print("="*70)
print("æ‰¹é‡å›¾åƒåˆ†å‰²å·¥å…· - SAM Batch Processing")
print("="*70)
print(f"\né…ç½®ä¿¡æ¯ï¼š")
print(f"  - è¾“å…¥ç›®å½•ï¼š{INPUT_DIR}")
print(f"  - è¾“å‡ºç›®å½•ï¼š{OUTPUT_DIR}")
print(f"  - æ¨¡å‹ç±»å‹ï¼š{MODEL_TYPE}")
print(f"  - å›¾åƒç¼©æ”¾ï¼š{'å¯ç”¨' if RESIZE_ENABLED else 'ç¦ç”¨'} (æœ€å¤§è¾¹é•¿: {MAX_IMAGE_SIZE}px)")
print(f"  - æ©ç æ¨¡å¼ï¼š{'åè½¬(æ©ç é»‘/èƒŒæ™¯ç™½)' if INVERT_MASK else 'æ­£å¸¸(æ©ç ç™½/èƒŒæ™¯é»‘)'}")
print(f"  - è·³è¿‡å·²å¤„ç†ï¼š{SKIP_EXISTING}")

# åˆ›å»ºè¾“å‡ºç›®å½•å’Œæ—¥å¿—ç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

# è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
image_extensions = ['.png']
image_files = []

for ext in image_extensions:
    image_files.extend(Path(INPUT_DIR).glob(f"*{ext}"))
    image_files.extend(Path(INPUT_DIR).glob(f"*{ext.upper()}"))

# ä¿æŒrealæ–‡ä»¶å¤¹é‡Œçš„é¡ºåº
# image_files = sorted(list(set(image_files)))  # å»é‡å¹¶æ’åº


print(f"\næ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")

if len(image_files) == 0:
    print(f"âŒ é”™è¯¯ï¼šåœ¨ {INPUT_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
    sys.exit(1)

# æ£€æŸ¥å·²å¤„ç†çš„å›¾ç‰‡
if SKIP_EXISTING:
    unprocessed_files = []
    for img_file in image_files:
        output_filename = img_file.stem + ".png"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        if not os.path.exists(output_path):
            unprocessed_files.append(img_file)
    
    skipped_count = len(image_files) - len(unprocessed_files)
    if skipped_count > 0:
        print(f"  - è·³è¿‡å·²å¤„ç†ï¼š{skipped_count} å¼ ")
        print(f"  - å¾…å¤„ç†ï¼š{len(unprocessed_files)} å¼ ")
    
    image_files = unprocessed_files

if len(image_files) == 0:
    print("\nâœ… æ‰€æœ‰å›¾ç‰‡å·²å¤„ç†å®Œæˆï¼")
    sys.exit(0)

# åŠ è½½ SAM æ¨¡å‹
print(f"\næ­£åœ¨åŠ è½½ SAM æ¨¡å‹...")
device = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"  - ä½¿ç”¨è®¾å¤‡ï¼š{device}")

if device == "cuda:0":
    print(f"  - GPUåç§°ï¼š{torch.cuda.get_device_name(0)}")
    print(f"  - GPUæ˜¾å­˜ï¼š{torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

try:
    sam = sam_model_registry[MODEL_TYPE](checkpoint=CKPT_PATH)
    sam.to(device=device)
    print(f"  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"  âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
    sys.exit(1)

# åˆ›å»ºæ©ç ç”Ÿæˆå™¨
mask_generator = SamAutomaticMaskGenerator(
    model=sam,
    **SAM_PARAMS
)

# ç»Ÿè®¡ä¿¡æ¯
stats = {
    'success': 0,
    'failed': 0,
    'total_time': 0,
    'failed_files': []
}

# æ‰¹é‡å¤„ç†å‡½æ•°
def process_image(image_path):
    """å¤„ç†å•å¼ å›¾ç‰‡"""
    try:
        # è¯»å–å›¾ç‰‡ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
        with open(image_path, 'rb') as f:
            image_data = np.frombuffer(f.read(), np.uint8)
            image_bgr = cv2.imdecode(image_data, cv2.IMREAD_COLOR)
        
        if image_bgr is None:
            return False, "æ— æ³•è¯»å–å›¾ç‰‡"
        
        # è·å–åŸå§‹å°ºå¯¸
        original_height, original_width = image_bgr.shape[:2]
        
        # å¦‚æœå¯ç”¨ç¼©æ”¾ä¸”å›¾åƒè¿‡å¤§ï¼Œåˆ™ç¼©å°å›¾åƒ
        if RESIZE_ENABLED:
            max_dim = max(original_height, original_width)
            if max_dim > MAX_IMAGE_SIZE:
                scale = MAX_IMAGE_SIZE / max_dim
                new_width = int(original_width * scale)
                new_height = int(original_height * scale)
                image_bgr = cv2.resize(image_bgr, (new_width, new_height), interpolation=cv2.INTER_AREA)
        
        # è½¬æ¢é¢œè‰²ç©ºé—´
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        
        # ç”Ÿæˆæ©ç 
        masks = mask_generator.generate(image_rgb)
        
        if len(masks) == 0:
            return False, "æœªç”Ÿæˆä»»ä½•æ©ç "
        
        # é€‰æ‹©é¢ç§¯ç¬¬äºŒå¤§çš„æ©ç 
        if len(masks) < 2:
            # å¦‚æœåªæœ‰ä¸€ä¸ªmaskï¼Œé€€è€Œæ±‚å…¶æ¬¡é€‰æ‹©é¢ç§¯æœ€å¤§çš„
            roi = max(masks, key=lambda m: m["area"])
        else:
            sorted_masks = sorted(masks, key=lambda m: m["area"], reverse=True)
            roi = sorted_masks[1]
        roi_mask = (roi["segmentation"].astype(np.uint8) * 255)
        
        # å¦‚æœå›¾åƒè¢«ç¼©æ”¾äº†ï¼Œå°†æ©ç æ¢å¤åˆ°åŸå§‹å°ºå¯¸
        if RESIZE_ENABLED and (roi_mask.shape[0] != original_height or roi_mask.shape[1] != original_width):
            roi_mask = cv2.resize(roi_mask, (original_width, original_height), interpolation=cv2.INTER_NEAREST)
        
        # æ ¹æ®é…ç½®åè½¬æ©ç ï¼ˆæ©ç åŒºåŸŸå˜é»‘è‰²ï¼ŒèƒŒæ™¯å˜ç™½è‰²ï¼‰
        if INVERT_MASK:
            roi_mask = 255 - roi_mask  # åè½¬ï¼š0å˜255ï¼Œ255å˜0
        
        # ä¿å­˜æ©ç ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
        output_filename = image_path.stem + ".png"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        
        success, encoded_image = cv2.imencode('.png', roi_mask)
        if success:
            with open(output_path, 'wb') as f:
                f.write(encoded_image.tobytes())
            return True, f"æˆåŠŸ (ç”Ÿæˆ{len(masks)}ä¸ªåŒºåŸŸ)"
        else:
            return False, "ä¿å­˜å¤±è´¥"
            
    except Exception as e:
        return False, str(e)

# å¼€å§‹æ‰¹é‡å¤„ç†
print("\n" + "="*70)
print("å¼€å§‹æ‰¹é‡å¤„ç†")
print("="*70 + "\n")

start_time = time.time()

try:
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
    for img_file in tqdm(image_files, desc="å¤„ç†è¿›åº¦", unit="å¼ "):
        img_start_time = time.time()
        
        success, message = process_image(img_file)
        
        img_time = time.time() - img_start_time
        stats['total_time'] += img_time
        
        if success:
            stats['success'] += 1
            # tqdm.write(f"âœ… {img_file.name}: {message} ({img_time:.2f}ç§’)")
        else:
            stats['failed'] += 1
            stats['failed_files'].append((img_file.name, message))
            tqdm.write(f"âŒ {img_file.name}: {message}")
        
        # æ¸…ç†GPUæ˜¾å­˜ï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰
        if device == "cuda:0":
            try:
                torch.cuda.empty_cache()  # æ¸…ç©ºç¼“å­˜
                torch.cuda.synchronize()  # åŒæ­¥GPUæ“ä½œ
            except RuntimeError as e:
                # å¦‚æœæ¸…ç†æ˜¾å­˜å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
                tqdm.write(f"âš ï¸  æ˜¾å­˜æ¸…ç†å¤±è´¥: {str(e)}")
                
except KeyboardInterrupt:
    print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
except Exception as e:
    print(f"\n\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
finally:
    total_time = time.time() - start_time

# è¾“å‡ºç»Ÿè®¡ç»“æœ
print("\n" + "="*70)
print("å¤„ç†å®Œæˆ - ç»Ÿè®¡æŠ¥å‘Š")
print("="*70)

print(f"\nå¤„ç†ç»“æœï¼š")
print(f"  âœ… æˆåŠŸï¼š{stats['success']} å¼ ")
print(f"  âŒ å¤±è´¥ï¼š{stats['failed']} å¼ ")
print(f"  ğŸ“Š æˆåŠŸç‡ï¼š{stats['success']/(stats['success']+stats['failed'])*100:.1f}%")

print(f"\næ—¶é—´ç»Ÿè®¡ï¼š")
print(f"  - æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’")
print(f"  - å¹³å‡æ¯å¼ ï¼š{stats['total_time']/(stats['success']+stats['failed']):.2f} ç§’")

if stats['failed'] > 0:
    print(f"\nå¤±è´¥çš„æ–‡ä»¶ï¼š")
    for filename, reason in stats['failed_files']:
        print(f"  - {filename}: {reason}")

print(f"\nè¾“å‡ºç›®å½•ï¼š{OUTPUT_DIR}")
print("="*70)

# ç”Ÿæˆå¤„ç†æ—¥å¿—
timestamp = time.strftime('%Y%m%d_%H%M%S')
log_filename = f"batch_processing_mask{timestamp}.log"
log_path = os.path.join(LOG_DIR, log_filename)

with open(log_path, 'w', encoding='utf-8') as f:
    f.write("="*70 + "\n")
    f.write("æ‰¹é‡å›¾åƒåˆ†å‰²å¤„ç†æ—¥å¿—\n")
    f.write("="*70 + "\n\n")
    f.write(f"å¤„ç†æ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"è¾“å…¥ç›®å½•ï¼š{INPUT_DIR}\n")
    f.write(f"è¾“å‡ºç›®å½•ï¼š{OUTPUT_DIR}\n")
    f.write(f"æ¨¡å‹ç±»å‹ï¼š{MODEL_TYPE}\n")
    f.write(f"æ©ç æ¨¡å¼ï¼š{'åè½¬(æ©ç é»‘/èƒŒæ™¯ç™½)' if INVERT_MASK else 'æ­£å¸¸(æ©ç ç™½/èƒŒæ™¯é»‘)'}\n")
    f.write(f"ä½¿ç”¨è®¾å¤‡ï¼š{device}\n\n")
    f.write(f"å¤„ç†ç»“æœï¼š\n")
    f.write(f"  - æˆåŠŸï¼š{stats['success']} å¼ \n")
    f.write(f"  - å¤±è´¥ï¼š{stats['failed']} å¼ \n")
    f.write(f"  - æˆåŠŸç‡ï¼š{stats['success']/(stats['success']+stats['failed'])*100:.1f}%\n\n")
    f.write(f"æ—¶é—´ç»Ÿè®¡ï¼š\n")
    f.write(f"  - æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’\n")
    f.write(f"  - å¹³å‡æ¯å¼ ï¼š{stats['total_time']/(stats['success']+stats['failed']):.2f} ç§’\n\n")
    
    if stats['failed'] > 0:
        f.write("å¤±è´¥çš„æ–‡ä»¶ï¼š\n")
        for filename, reason in stats['failed_files']:
            f.write(f"  - {filename}: {reason}\n")

print(f"\næ—¥å¿—å·²ä¿å­˜åˆ°ï¼š{log_path}")

